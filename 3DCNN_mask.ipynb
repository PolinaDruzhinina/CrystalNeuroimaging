{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/polina/mri-interpretation/2da0eac310ef409a8cb1f270416be606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade comet_ml\n",
    "from comet_ml import Experiment\n",
    "    \n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"0EKSrlH9OVngYfgQCrauwqLEt\",\n",
    "                        project_name=\"mri-interpretation\", workspace=\"polina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import torchio\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.transforms import *\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mri/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/mri/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/mri/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import nilearn\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import HCP_MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:2\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 17 03:30:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    32W / 250W |   1427MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    33W / 250W |  13460MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  Off  | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE...  Off  | 00000000:13:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    32W / 250W |    833MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    33W / 250W |  15460MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    32W / 250W |   2961MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE...  Off  | 00000000:8E:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    33W / 250W |  13628MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE...  Off  | 00000000:91:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    32W / 250W |  11949MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     56441      C   /root/miniconda3/bin/python                 1417MiB |\n",
      "|    1      6693      C   /usr/bin/python3                             927MiB |\n",
      "|    1     17372      C   /usr/bin/python3                           12523MiB |\n",
      "|    3     50529      C   python                                       823MiB |\n",
      "|    4     12190      C   /usr/bin/python3                            7477MiB |\n",
      "|    4     15333      C   /usr/bin/python3                            7973MiB |\n",
      "|    5     44092      C   /usr/bin/python3                            2951MiB |\n",
      "|    6      6817      C   /usr/bin/python3                            1905MiB |\n",
      "|    6     12190      C   /usr/bin/python3                           11713MiB |\n",
      "|    7     32076      C   /usr/bin/python3                           11939MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/home/mri/datasets/adni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_central_cuts(img, title=\"\", t=None):\n",
    "    \"\"\"\n",
    "    param image: tensor or np array of shape (CxDxHxW) if t is None\n",
    "    param image: tensor or np array of shape (TxCxDxHxW) if t is not None\n",
    "    \"\"\"\n",
    "    if t is not None:\n",
    "        img = img[t]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3 * 6, 6))\n",
    "    fig.suptitle(title)\n",
    "    axes[0].imshow(img[0, img.shape[1] // 2, :, :])\n",
    "    axes[1].imshow(img[0, :, img.shape[2] // 2, :])\n",
    "    axes[2].imshow(img[0, :, :, img.shape[3] // 2])\n",
    "    plt.show()\n",
    "# plot_central_cuts(nilearn.image.get_data(img)[np.newaxis,:], title=\"ex\", t = None)\n",
    "# plot_central_cuts(img_crop, title=\"ex\", t = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MRI = '/home/mri/datasets/HCP_T1_fsl/HCP_T1_pm'\n",
    "data_dir = pathlib.Path('/home/mri/datasets/adni')\n",
    "behavioral_path = os.path.join('/home/mri/datasets/adni', 'unrestricted_hcp_freesurfer.csv')\n",
    "hcp_type = 'MPR1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absmax(dataset):\n",
    "    absmax = 0.\n",
    "    for (img, target) in dataset:\n",
    "        img = torch.FloatTensor(img).to(device)\n",
    "        absmax = max(absmax, img.abs().max().item())\n",
    "        del img, target\n",
    "    return absmax\n",
    "\n",
    "def AbsMaxScale(img, absmax):\n",
    "    return img / absmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCP absmax before normalization: 435.0126647949219\n",
      "Dataset size: 1112\n",
      "Labels distribution: (array([0, 1]), array([605, 507]))\n",
      "\n",
      "Example:\n",
      "Image shape: torch.Size([1, 176, 260, 230])\n",
      "Type: <class 'torch.Tensor'>\n",
      "Target: 1\n"
     ]
    }
   ],
   "source": [
    "hcp_dataset = HCP_MRI(\n",
    "    paths= PATH_TO_MRI,\n",
    "    target_path= behavioral_path,\n",
    "    load_online=True,\n",
    "    hcp_type = hcp_type,\n",
    "    coord_min=(40,25,55),\n",
    "    img_shape=(176, 260, 230)\n",
    ")\n",
    "hcp_absmax = 435.0126647949219 # get_absmax(la5_dataset)\n",
    "hcp_dataset.transform = functools.partial(AbsMaxScale, absmax=hcp_absmax)\n",
    "\n",
    "transform = Compose([\n",
    "#     BrightnessContrast(),\n",
    "#     GaussNoise(),\n",
    "#     Rotate(),\n",
    "    ToTensor(),\n",
    "])\n",
    "hcp_dataset.transform = transform\n",
    "print(\"HCP absmax before normalization: {}\".format(hcp_absmax))\n",
    "print(\"Dataset size: {}\".format(len(hcp_dataset)))\n",
    "print(\"Labels distribution: {}\\n\".format(np.unique(hcp_dataset.labels, return_counts=True)))\n",
    "\n",
    "print(\"Example:\")\n",
    "img, target = hcp_dataset[0]\n",
    "print(\"Image shape: {}\".format(img.shape))\n",
    "print(\"Type: {}\".format(type(img)))\n",
    "print(\"Target: {}\".format(target))\n",
    "plot_central_cuts(img, title=\"ex\", t = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hidden layers 1, 2 and 3\n",
    "hidden = lambda c_in, c_out: nn.Sequential(\n",
    "    nn.Conv3d(c_in, c_out, (3,3,3)), # Convolutional layer\n",
    "    nn.BatchNorm3d(c_out), # Batch Normalization layer\n",
    "    nn.ReLU(), # Activational layer\n",
    "    nn.MaxPool3d(3) # Pooling layer\n",
    ")\n",
    "\n",
    "class MriNet(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNet, self).__init__()\n",
    "        self.hidden1 = hidden(1, c)\n",
    "        self.hidden2 = hidden(c, 2*c)\n",
    "        self.hidden3 = hidden(2*c, 4*c)\n",
    "        self.hidden4 = hidden(4*c, 4*c)\n",
    "        self.linear = nn.Linear(256, 2)#16000\n",
    "#         self.linear = nn.Linear(128*5*5*5, 2)#16000\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "#         print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "c = 32\n",
    "model = MriNet(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [0, 1, 2, 3] GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNet(\n",
       "    (hidden1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden4): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (flatten): Flatten()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "      d_ids= [0,1,2,3]\n",
    "      print(\"Let's use\", d_ids, \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      model = nn.DataParallel(model, device_ids=d_ids)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split(np.arange(len(hcp_dataset)), hcp_dataset.labels, test_size=0.2, stratify=hcp_dataset.labels, random_state=42)\n",
    "train_loader = torch_data.DataLoader(torch_data.Subset(hcp_dataset, X_train_ind),\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=4)\n",
    "val_loader = torch_data.DataLoader(torch_data.Subset(hcp_dataset, X_test_ind),\n",
    "                                    shuffle=False,\n",
    "                                    batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR =  '/home/Druzhinina/project/test_old/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) #return ADAM?\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_accuracy(net, data_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    for data, target in tqdm(data_loader):\n",
    "        data = data.to(device,dtype=torch.float)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = net(data)\n",
    "        pred = out.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        del data, target\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    return accuracy.item()\n",
    "\n",
    "def get_loss(net, data_loader):\n",
    "    net.eval()\n",
    "    loss = 0 \n",
    "    for data, target in tqdm(data_loader):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        target = target.to(device)\n",
    "    \n",
    "        out = net(data)\n",
    "        loss += criterion(out, target).item()*len(data)\n",
    "\n",
    "        del data, target, out \n",
    "\n",
    "    return loss / len(data_loader.dataset)\n",
    "\n",
    "\n",
    "def train(epochs, net, criterion, optimizer, train_loader, val_loader, scheduler=None, verbose=True, save=False, experiment= False):\n",
    "    best_val_loss = 100000 #100_000\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    train_loss_list.append(get_loss(net, train_loader))\n",
    "    val_loss_list.append(get_loss(net, val_loader))\n",
    "    train_acc_list.append(get_accuracy(net, train_loader))\n",
    "    val_acc_list.append(get_accuracy(net, val_loader))\n",
    "    if verbose:\n",
    "        print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(0, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
    "\n",
    "    net.to(device)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        for X, y in train_loader:\n",
    "            # Perform one step of minibatch stochastic gradient descent\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             print(type(X))\n",
    "            out = net(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del X, y, out, loss #freeing gpu space\n",
    "            \n",
    "        \n",
    "        # define NN evaluation, i.e. turn off dropouts, batchnorms, etc.\n",
    "        net.eval()\n",
    "        for X, y in val_loader:\n",
    "            # Compute the validation loss\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device)\n",
    "            out = net(X)\n",
    "            del X, y, out #freeing gpu space\n",
    "         \n",
    "        train_loss_list.append(get_loss(net, train_loader))\n",
    "        val_loss_list.append(get_loss(net, val_loader))\n",
    "        train_acc_list.append(get_accuracy(net, train_loader))\n",
    "        val_acc_list.append(get_accuracy(net, val_loader))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_acc_list[-1])\n",
    "\n",
    "        if save and val_acc_list[-1] > best_val_acc:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + 'best_acc_model_' + model_name)    \n",
    "            best_val_acc = val_acc_list[-1]\n",
    "            \n",
    "        if save and val_loss_list[-1] < best_val_loss:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + 'best_val_loss_model_' + model_name)\n",
    "            best_val_loss = val_loss_list[-1]\n",
    "            \n",
    "        if save and epoch%10==0:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + str(epoch) + '_epoch_model_' + model_name)\n",
    "            \n",
    "        freq = 1\n",
    "        if verbose and epoch%freq==0:\n",
    "            print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
    "        if experiment:\n",
    "                experiment.log_metric(\"train_loss\", train_loss_list[-1])\n",
    "                experiment.log_metric(\"validate_loss\", val_loss_list[-1])\n",
    "                experiment.log_metric(\"train_acc\", train_acc_list[-1])\n",
    "                experiment.log_metric(\"validate_acc\", val_acc_list[-1])\n",
    "                experiment.log_epoch_end(epoch)\n",
    "    return train_loss_list, val_loss_list, train_acc_list, val_acc_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.set_name(\"3DCNN_all_subject_baseline_Adam_5e-5_sch_05_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '_all_subject_adam-4_sch'\n",
    "experiment.set_name(\"3DCNN_all_subject_baseline_Adam_5e-5_sch_05_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-26-10bbc67a09e3>\", line 32, in forward\n    x = self.features(x)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 100, in forward\n    input = module(input)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 481, in forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: CUDA out of memory. Tried to allocate 3.95 GiB (GPU 0; 15.90 GiB total capacity; 13.98 GiB already allocated; 1.19 GiB free; 13.99 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-db9934553f6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-29f98e7d6265>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, net, criterion, optimizer, train_loader, val_loader, scheduler, verbose, save, experiment)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-29f98e7d6265>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(net, data_loader)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"<ipython-input-26-10bbc67a09e3>\", line 32, in forward\n    x = self.features(x)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 100, in forward\n    input = module(input)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 481, in forward\n    self.padding, self.dilation, self.groups)\nRuntimeError: CUDA out of memory. Tried to allocate 3.95 GiB (GPU 0; 15.90 GiB total capacity; 13.98 GiB already allocated; 1.19 GiB free; 13.99 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "EPOCHS = 40\n",
    "\n",
    "train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=True, experiment= experiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss history', fontsize=18)\n",
    "plt.plot(train_loss_list[1:], label='Train')\n",
    "plt.plot(val_loss_list[1:], label='Validation')\n",
    "plt.xlabel('# of epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy history', fontsize=18)\n",
    "plt.plot(train_acc_list, label='Train')\n",
    "plt.plot(val_acc_list, label='Validation')\n",
    "plt.xlabel('# of epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNet(\n",
       "    (hidden1): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (hidden4): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (linear): Linear(in_features=16000, out_features=2, bias=True)\n",
       "    (flatten): Flatten()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(CHECKPOINTS_DIR+'best_model_lr'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.38461303710938"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/Druzhinina/project/checkpoints/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /home/Druzhinina/project/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'NetGrad_skull_drop_strip_bs42'\n",
    "# experiment.set_name(\"NetGrad_skull_drop_strip_Adam_5e-5_sch_05_2_bs42\")\n",
    "model_name = 'ex_test'\n",
    "experiment.set_name(\"ex_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNetGrad(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNetGrad, self).__init__()\n",
    "        self.features = nn.Sequential( \n",
    "                nn.Conv3d(1, c, kernel_size=3),\n",
    "                nn.BatchNorm3d(c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3),\n",
    "                \n",
    "                nn.Conv3d(c, 2*c, kernel_size=3),\n",
    "                nn.BatchNorm3d(2*c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3),\n",
    "                \n",
    "                nn.Conv3d(2*c, 4*c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(4*c),\n",
    "                nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=3),\n",
    "            nn.Flatten(),\n",
    "#             nn.Linear(in_features=4*c*5*5*5, out_features=2),\n",
    "            nn.Linear(in_features=35840, out_features=2)\n",
    "        )\n",
    "        self.gradients = None\n",
    "        \n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "c = 32\n",
    "model = MriNetGrad(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [2, 1, 0, 3] GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten()\n",
       "      (2): Linear(in_features=35840, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "      d_ids= [2,1,0,3]\n",
    "      print(\"Let's use\", d_ids, \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      model = nn.DataParallel(model, device_ids=d_ids)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MriNetGrad(C).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = nn.NLLLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) #return ADAM?\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e66946ff1cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "EPOCHS = 20\n",
    "\n",
    "train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=True, experiment= experiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [01:15<00:00,  1.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.61883544921875"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/mri/datasets/adni/y_randomize', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten()\n",
       "      (2): Linear(in_features=35840, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/Druzhinina/project/checkpoints_skull/best_acc_model_NetGrad_skull_strip_bs42'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [01:15<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.06726837158203"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten()\n",
       "      (2): Linear(in_features=35840, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/Druzhinina/project/checkpoints_skull/best_val_loss_model_NetGrad_skull_strip_bs42'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [01:15<00:00,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.06726837158203"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR =  '/home/Druzhinina/project/checkpoints_work_gradcam/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNetGrad(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNetGrad, self).__init__()\n",
    "        self.features = nn.Sequential( \n",
    "                nn.Conv3d(1, c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3, stride=2,),\n",
    "                \n",
    "                nn.Conv3d(c, 2*c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(2*c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "                \n",
    "                nn.Conv3d(2*c, 4*c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(4*c),\n",
    "                nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1896960, out_features=2), #4*c*5*7*5\n",
    "        )\n",
    "        self.gradients = None\n",
    "        \n",
    "     \n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "c = 32\n",
    "model = MriNetGrad(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [2, 3] GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=1896960, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "      d_ids= [2,3]\n",
    "      print(\"Let's use\", d_ids, \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      model = nn.DataParallel(model, device_ids=d_ids)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.NLLLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) #return ADAM?\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-130a4d58751e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_checkpoints_work_gradcam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3DCNN_checkpoints_work_gradcam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = '_checkpoints_work_gradcam'\n",
    "experiment.set_name(\"3DCNN_checkpoints_work_gradcam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [07:41<00:00,  2.07s/it]\n",
      "100%|██████████| 112/112 [02:14<00:00,  1.20s/it]\n",
      "100%|██████████| 223/223 [07:04<00:00,  1.90s/it]\n",
      "100%|██████████| 112/112 [01:44<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00/40 || Loss:  Train 30.1371 | Validation 30.6961\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "EPOCHS = 40\n",
    "\n",
    "train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=True, experiment= experiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=1896960, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/mri/Druzhinina/project/checkpoints_work_gradcam/best_acc_model__checkpoints_work_gradcam'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [01:30<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.96412658691406"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
