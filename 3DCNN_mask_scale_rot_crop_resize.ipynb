{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/polina/mri-interpretation/c7030e1a4da24eb1810d68598f624da9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade comet_ml\n",
    "from comet_ml import Experiment\n",
    "    \n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"0EKSrlH9OVngYfgQCrauwqLEt\",\n",
    "                        project_name=\"mri-interpretation\", workspace=\"polina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as torch_data\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "import os\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import torchio\n",
    "import nibabel as nib\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.transforms import *\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import HCP_MRI_crop_resize\n",
    "# from data import HCP_MRI_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:3\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 20 18:33:01 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:13:00.0 Off |                    0 |\n",
      "| N/A   23C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    25W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE...  Off  | 00000000:8E:00.0 Off |                    0 |\n",
      "| N/A   22C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE...  Off  | 00000000:91:00.0 Off |                    0 |\n",
      "| N/A   24C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/data/adni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_central_cuts(img, title=\"\", t=None):\n",
    "    \"\"\"\n",
    "    param image: tensor or np array of shape (CxDxHxW) if t is None\n",
    "    param image: tensor or np array of shape (TxCxDxHxW) if t is not None\n",
    "    \"\"\"\n",
    "    if t is not None:\n",
    "        img = img[t]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3 * 6, 6))\n",
    "    fig.suptitle(title)\n",
    "    axes[0].imshow(img[0, img.shape[1] // 2, :, :])\n",
    "    axes[1].imshow(img[0, :, img.shape[2] // 2, :])\n",
    "    axes[2].imshow(img[0, :, :, img.shape[3] // 2])\n",
    "    plt.show()\n",
    "# plot_central_cuts(nilearn.image.get_data(img)[np.newaxis,:], title=\"ex\", t = None)\n",
    "# plot_central_cuts(img_crop, title=\"ex\", t = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_MRI = '/data/hcp/HCP_T1_pm'\n",
    "PATH_TO_MRI = '/home/crop_data_resize_np'\n",
    "data_dir = pathlib.Path('/data/adni')\n",
    "behavioral_path = os.path.join('/data/adni', 'unrestricted_hcp_freesurfer.csv')\n",
    "hcp_type = 'MPR1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absmax(dataset):\n",
    "    absmax = 0.\n",
    "    for (img, target) in dataset:\n",
    "        img = torch.FloatTensor(img).to(device)\n",
    "        absmax = max(absmax, img.abs().max().item())\n",
    "        del img, target\n",
    "    return absmax\n",
    "\n",
    "def AbsMaxScale(img, absmax):\n",
    "    return img / absmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCP absmax before normalization: 435.0126647949219\n",
      "Train Dataset size: 889\n",
      "Test Dataset size: 223\n",
      "Labels distribution: (array([0, 1]), array([482, 407]))\n",
      "\n",
      "Train example:\n",
      "Image shape: torch.Size([1, 176, 260, 230])\n",
      "Type: <class 'torch.Tensor'>\n",
      "Target: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val example:\n",
      "Image shape: torch.Size([1, 176, 260, 230])\n",
      "Type: <class 'torch.Tensor'>\n",
      "Target: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(pd.read_csv(behavioral_path), test_size=0.2, random_state=42) \n",
    "train_hcp_dataset = HCP_MRI_crop_resize(\n",
    "    paths= PATH_TO_MRI,\n",
    "    target_path= X_train,\n",
    "    load_online=True,\n",
    "    hcp_type = hcp_type,\n",
    "    coord_min=(40, 40, 30, 30, 45, 45), #40,25,55,( 15, 15, 0, 19, 34, 51)\n",
    "    img_shape=(176, 260, 230) #176, 260, 230, (226, 301, 235), 256, 320, 320\n",
    ")\n",
    "val_hcp_dataset = HCP_MRI_crop_resize(\n",
    "    paths= PATH_TO_MRI,\n",
    "    target_path= X_test,\n",
    "    load_online=True,\n",
    "    hcp_type = hcp_type,\n",
    "    coord_min=(40, 40, 30, 30, 45, 45), #40,25,55\n",
    "    img_shape=(176, 260, 230) #176, 260, 230, 226, 301, 235), 256, 320, 320\n",
    ")\n",
    "\n",
    "hcp_absmax = 435.0126647949219 # get_absmax(la5_dataset)\n",
    "train_hcp_dataset.transform = functools.partial(AbsMaxScale, absmax=hcp_absmax)\n",
    "val_hcp_dataset.transform = functools.partial(AbsMaxScale, absmax=hcp_absmax)\n",
    "# train_transform = Compose([\n",
    "#     ToTensor(),\n",
    "# #     BrightnessContrast(),\n",
    "# #     GaussNoise(),\n",
    "#     RandomRotation(degrees = 35),\n",
    "#     RandomAffine(degrees = 0, scale=(0.8, 1.2)) #0.8,1.2\n",
    "# #     ToTensor(),\n",
    "# ])\n",
    "\n",
    "# val_transform = Compose([\n",
    "# #     BrightnessContrast(),\n",
    "# #     GaussNoise(),\n",
    "# #     Rotate(),\n",
    "#     ToTensor(),\n",
    "# ])\n",
    "train_transform = torchio.transforms.Compose([\n",
    "#     BrightnessContrast(),\n",
    "#     GaussNoise(),\n",
    "    torchio.transforms.RandomAffine(scales=(0.8, 1.2), degrees = 10),\n",
    "#     ToTensor(),\n",
    "])\n",
    "\n",
    "train_hcp_dataset.transform = train_transform\n",
    "# val_hcp_dataset.transform = val_transform\n",
    "print(\"HCP absmax before normalization: {}\".format(hcp_absmax))\n",
    "print(\"Train Dataset size: {}\".format(len(train_hcp_dataset)))\n",
    "print(\"Test Dataset size: {}\".format(len(val_hcp_dataset)))\n",
    "print(\"Labels distribution: {}\\n\".format(np.unique(train_hcp_dataset.labels, return_counts=True)))\n",
    "\n",
    "print(\"Train example:\")\n",
    "img, target = train_hcp_dataset[0]\n",
    "print(\"Image shape: {}\".format(img.shape))\n",
    "print(\"Type: {}\".format(type(img)))\n",
    "print(\"Target: {}\".format(target))\n",
    "plot_central_cuts(img, title=\"ex\", t = None)\n",
    "print(\"Val example:\")\n",
    "img, target = val_hcp_dataset[0]\n",
    "print(\"Image shape: {}\".format(img.shape))\n",
    "print(\"Type: {}\".format(type(img)))\n",
    "print(\"Target: {}\".format(target))\n",
    "plot_central_cuts(img, title=\"ex\", t = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10062980651855469\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "img = np.load('/home/crop_data_resize_np/111514_3T_T1w_MPR1_bet_mask_crop.nii.gz.npy') \n",
    "print( time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'crop_data': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r crop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "100%|██████████| 1112/1112 [1:31:18<00:00,  4.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# from skimage.transform import resize\n",
    "# from tqdm import tqdm\n",
    "# PATH_TO_MRI = '/data/hcp/HCP_T1_pm'\n",
    "# mri_paths = {\n",
    "#             \"participant_id\": [],\n",
    "#             \"path\": []\n",
    "#         }\n",
    "# bd = pd.read_csv(behavioral_path)\n",
    "# bd.set_index('Subject',inplace=True)\n",
    "# y_gender = []\n",
    "        \n",
    "# for patient_folder_name in os.listdir(PATH_TO_MRI):\n",
    "#     if 'nii' in patient_folder_name:\n",
    "#             sub = patient_folder_name[:6]\n",
    "#             if int(sub) in bd.index.values:\n",
    "#                 full_path = '{}/{}_3T_T1w_MPR1_bet_mask.nii.gz'.format(PATH_TO_MRI, sub)\n",
    "#                 if os.path.exists(full_path):\n",
    "#                     mri_paths[\"participant_id\"].append(sub)\n",
    "#                     mri_paths[\"path\"].append(full_path)\n",
    "#                     y_gender.append(bd['Gender'][int(sub)])\n",
    "\n",
    "# mri_paths = pd.DataFrame(mri_paths)\n",
    "    \n",
    "# mri_paths['Gender'] = y_gender\n",
    "# #         print(self.mri_paths['Gender'])\n",
    "# mri_paths = mri_paths[\"path\"].tolist()\n",
    "# for nii_path in tqdm(mri_paths):\n",
    "#             img = nib.load(nii_path).get_data()\n",
    "#             subj_bool = img != 0\n",
    "#     #         subj_bool = subj_bool.reshape( (256, 320, 320,1))\n",
    "#             ax_zero_cut = torch.from_numpy(subj_bool).max(dim=2).values.max(dim=1).values.data.numpy()\n",
    "#             ax_one_cut = torch.from_numpy(subj_bool).max(dim=2).values.max(dim=0).values.data.numpy()\n",
    "#             ax_two_cut = torch.from_numpy(subj_bool).max(dim=1).values.max(dim=0).values.data.numpy()\n",
    "#             ax_zero_min, ax_zero_max = np.where(ax_zero_cut)[0][[0, -1]]\n",
    "#             ax_one_min, ax_one_max = np.where(ax_one_cut)[0][[0, -1]]\n",
    "#             ax_two_min, ax_two_max = np.where(ax_two_cut)[0][[0, -1]]\n",
    "#             img = img[\n",
    "#                       ax_zero_min:ax_zero_max + 1,\n",
    "#                       ax_one_min:ax_one_max + 1,\n",
    "#                       ax_two_min:ax_two_max + 1,\n",
    "#                       ]\n",
    "#             img = resize(img, (176, 260, 230))\n",
    "                \n",
    "#             np.save('/home/crop_data_resize_np/{}_3T_T1w_MPR1_bet_mask_crop'.format(nii_path[-34:-28]), img)\n",
    "# #             nib.save(nib.Nifti1Image(img, affine = np.eye(4)), '/home/crop_data_resize/{}_3T_T1w_MPR1_bet_mask_crop.nii.gz'.format(nii_path[-39:-33]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                                 Size  Used Avail Use% Mounted on\r\n",
      "overlay                                    3.7T  2.0T  1.7T  55% /\r\n",
      "tmpfs                                       64M     0   64M   0% /dev\r\n",
      "tmpfs                                       63G     0   63G   0% /sys/fs/cgroup\r\n",
      "shm                                         64M  4.0K   64M   1% /dev/shm\r\n",
      "192.168.1.2:/home/mri/Druzhinina/project   9.1T  9.1T  1.0M 100% /home\r\n",
      "10.30.99.245:/home/datasets/adni            13T   12T   75G 100% /data/adni\r\n",
      "192.168.1.2:/home/mri/datasets/HCP_T1_fsl  9.1T  9.1T  1.0M 100% /data/hcp\r\n",
      "/dev/sdb1                                  3.7T  2.0T  1.7T  55% /etc/hosts\r\n",
      "tmpfs                                       63G   12K   63G   1% /proc/driver/nvidia\r\n",
      "/dev/mapper/vg_local-lv_root                28G   14G   13G  53% /usr/bin/nvidia-smi\r\n",
      "udev                                        63G     0   63G   0% /dev/nvidia3\r\n",
      "tmpfs                                       63G     0   63G   0% /proc/acpi\r\n",
      "tmpfs                                       63G     0   63G   0% /proc/scsi\r\n",
      "tmpfs                                       63G     0   63G   0% /sys/firmware\r\n"
     ]
    }
   ],
   "source": [
    "# !df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5096\t./.ipynb_checkpoints\n",
      "104\t./checkpoints/.ipynb_checkpoints\n",
      "159111148\t./checkpoints\n",
      "5904\t./checkpoints_backup\n",
      "9552\t./masks/.ipynb_checkpoints\n",
      "40\t./masks/__pycache__\n",
      "4716\t./masks/img_without_skulstr/.ipynb_checkpoints\n",
      "10664\t./masks/img_without_skulstr\n",
      "0\t./masks/skull-worked_gradcam/.ipynb_checkpoints\n",
      "4124\t./masks/skull-worked_gradcam\n",
      "3332\t./masks/img_skull/.ipynb_checkpoints\n",
      "7024\t./masks/img_skull\n",
      "25296\t./masks/wandb/run-20201230_041102-3azna7la/logs\n",
      "9092\t./masks/wandb/run-20201230_041102-3azna7la/files/media/images\n",
      "9092\t./masks/wandb/run-20201230_041102-3azna7la/files/media\n",
      "9128\t./masks/wandb/run-20201230_041102-3azna7la/files\n",
      "34656\t./masks/wandb/run-20201230_041102-3azna7la\n",
      "34656\t./masks/wandb\n",
      "920\t./masks/Free_surfer(450)/.ipynb_checkpoints\n",
      "5016\t./masks/Free_surfer(450)\n",
      "196\t./masks/befor\n",
      "86936\t./masks\n",
      "4\t./.git/refs/heads\n",
      "0\t./.git/refs/tags\n",
      "4\t./.git/refs/remotes/origin\n",
      "4\t./.git/refs/remotes\n",
      "8\t./.git/refs\n",
      "0\t./.git/branches\n",
      "40\t./.git/hooks\n",
      "4\t./.git/info\n",
      "133701312\t./.git/objects/pack\n",
      "0\t./.git/objects/info\n",
      "212\t./.git/objects/15\n",
      "4\t./.git/objects/01\n",
      "60\t./.git/objects/b5\n",
      "252\t./.git/objects/c6\n",
      "4\t./.git/objects/07\n",
      "4\t./.git/objects/9b\n",
      "4\t./.git/objects/2a\n",
      "4\t./.git/objects/db\n",
      "732\t./.git/objects/e9\n",
      "1320\t./.git/objects/7b\n",
      "4\t./.git/objects/78\n",
      "4\t./.git/objects/d7\n",
      "4\t./.git/objects/c8\n",
      "384\t./.git/objects/af\n",
      "4\t./.git/objects/05\n",
      "4\t./.git/objects/fa\n",
      "36604\t./.git/objects/33\n",
      "732\t./.git/objects/3a\n",
      "268\t./.git/objects/d1\n",
      "16\t./.git/objects/e4\n",
      "4\t./.git/objects/7f\n",
      "240\t./.git/objects/4e\n",
      "560\t./.git/objects/fb\n",
      "1328\t./.git/objects/9c\n",
      "4\t./.git/objects/42\n",
      "4\t./.git/objects/70\n",
      "12\t./.git/objects/96\n",
      "4\t./.git/objects/43\n",
      "4\t./.git/objects/dc\n",
      "4\t./.git/objects/2e\n",
      "52\t./.git/objects/13\n",
      "72\t./.git/objects/cc\n",
      "1120\t./.git/objects/9e\n",
      "2608\t./.git/objects/3f\n",
      "1120\t./.git/objects/59\n",
      "2612\t./.git/objects/1b\n",
      "1120\t./.git/objects/14\n",
      "2612\t./.git/objects/c7\n",
      "2240\t./.git/objects/52\n",
      "2612\t./.git/objects/8f\n",
      "1120\t./.git/objects/a5\n",
      "2612\t./.git/objects/68\n",
      "2612\t./.git/objects/e1\n",
      "2612\t./.git/objects/35\n",
      "40040\t./.git/objects/02\n",
      "1120\t./.git/objects/86\n",
      "2612\t./.git/objects/8c\n",
      "1120\t./.git/objects/4d\n",
      "2612\t./.git/objects/7a\n",
      "2700\t./.git/objects/f0\n",
      "2712\t./.git/objects/2f\n",
      "1120\t./.git/objects/e3\n",
      "2620\t./.git/objects/6b\n",
      "600\t./.git/objects/00\n",
      "4\t./.git/objects/fc\n",
      "564\t./.git/objects/77\n",
      "1640\t./.git/objects/ea\n",
      "1636\t./.git/objects/6e\n",
      "1900\t./.git/objects/ed\n",
      "1852\t./.git/objects/c1\n",
      "1548\t./.git/objects/eb\n",
      "30776\t./.git/objects/ac\n",
      "6936\t./.git/objects/d8\n",
      "4\t./.git/objects/71\n",
      "4\t./.git/objects/17\n",
      "1316\t./.git/objects/88\n",
      "1320\t./.git/objects/7d\n",
      "30944\t./.git/objects/ab\n",
      "30820\t./.git/objects/b9\n",
      "30944\t./.git/objects/10\n",
      "30804\t./.git/objects/16\n",
      "37456\t./.git/objects/0c\n",
      "36196\t./.git/objects/94\n",
      "28\t./.git/objects/60\n",
      "576\t./.git/objects/4b\n",
      "632\t./.git/objects/34\n",
      "4\t./.git/objects/cb\n",
      "4\t./.git/objects/24\n",
      "4\t./.git/objects/4f\n",
      "4\t./.git/objects/f6\n",
      "4\t./.git/objects/c5\n",
      "36\t./.git/objects/fd\n",
      "4\t./.git/objects/36\n",
      "4\t./.git/objects/4c\n",
      "4\t./.git/objects/67\n",
      "4\t./.git/objects/22\n",
      "4\t./.git/objects/38\n",
      "134074456\t./.git/objects\n",
      "4\t./.git/logs/refs/heads\n",
      "4\t./.git/logs/refs/remotes/origin\n",
      "4\t./.git/logs/refs/remotes\n",
      "8\t./.git/logs/refs\n",
      "12\t./.git/logs\n",
      "134074544\t./.git\n",
      "24\t./__pycache__\n",
      "124434748\t./checkpoints_full\n",
      "91853880\t./checkpoints_skull\n",
      "63648\t./checkpoints_skull_drop\n",
      "22864172\t./test\n",
      "22922352\t./test_old\n",
      "0\t./checkpoints_work_gradcam/.ipynb_checkpoints\n",
      "137627632\t./checkpoints_work_gradcam\n",
      "22987208\t./checkpoints_augment_18_1.2\n",
      "875612\t./checkpoints_rot_55_batch4\n",
      "0\t./.Trash-0/files/Untitled Folder 1\n",
      "0\t./.Trash-0/files/crop_data/.ipynb_checkpoints\n",
      "7077384\t./.Trash-0/files/crop_data\n",
      "0\t./.Trash-0/files/crop_data_resize/.ipynb_checkpoints\n",
      "41651132\t./.Trash-0/files/crop_data_resize\n",
      "92584236\t./.Trash-0/files\n",
      "2236\t./.Trash-0/info\n",
      "92586472\t./.Trash-0\n",
      "23060340\t./checkpoints_rot_spcrop\n",
      "0\t./checkpoints_torchion_crop_resize\n",
      "0\t./crop_data_resize_np/.ipynb_checkpoints\n",
      "0\t./crop_data_resize_np\n",
      "832566440\t.\n"
     ]
    }
   ],
   "source": [
    "# !du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r ./.Trash-0/info/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch_data.DataLoader(train_hcp_dataset,\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=4)\n",
    "val_loader = torch_data.DataLoader(val_hcp_dataset,\n",
    "                                    shuffle=False,\n",
    "                                    batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_metric(net, data_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    true = []\n",
    "    for data, target in tqdm(data_loader):\n",
    "        data = data.to(device,dtype=torch.float)\n",
    "        target = target.to(device)\n",
    "\n",
    "        out = net(data)\n",
    "        pred = out.data.max(1)[1] # get the index of the max log-probability\n",
    "        true.append(pred.data.cpu().numpy())\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        del data, target, out, pred\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    true = np.concatenate(true)\n",
    "    roc_auc = roc_auc_score(data_loader.dataset.labels, true)\n",
    "    pr = precision_score(data_loader.dataset.labels,  true)\n",
    "    rec = recall_score(data_loader.dataset.labels, true)\n",
    "\n",
    "    return accuracy.item(), roc_auc, pr, rec\n",
    "\n",
    "def get_loss(net, data_loader):\n",
    "    net.eval()\n",
    "    loss = 0 \n",
    "    correct = 0\n",
    "    for data, target in tqdm(data_loader):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        target = target.to(device)\n",
    "    \n",
    "        out = net(data)\n",
    "        loss += criterion(out, target).item()*len(data)\n",
    "        pred = out.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "        del data, target, out \n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    return loss / len(data_loader.dataset), accuracy.item()\n",
    "\n",
    "\n",
    "def train(epochs, net, criterion, optimizer, train_loader, val_loader, scheduler=None, verbose=True, save=False, experiment= False):\n",
    "    best_val_loss = 100000 #100_000\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    loss, acc = get_loss(net, train_loader)\n",
    "    train_loss_list.append(loss)\n",
    "    train_acc_list.append(acc)\n",
    "    loss, acc = get_loss(net, val_loader)\n",
    "    val_loss_list.append(loss)\n",
    "    val_acc_list.append(acc)\n",
    "    del loss, acc\n",
    "    if verbose:\n",
    "        print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(0, epochs, train_loss_list[-1], val_loss_list[-1]))\n",
    "\n",
    "    net.to(device)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        for X, y in train_loader:\n",
    "            # Perform one step of minibatch stochastic gradient descent\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             print(type(X))\n",
    "            out = net(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*len(X)\n",
    "            pred = out.data.max(1)[1] # get the index of the max log-probability\n",
    "            train_correct += pred.eq(y.data).cpu().sum()\n",
    "            del X, y, out, loss #freeing gpu space\n",
    "        accuracy = 100. * train_correct / len(train_loader.dataset)\n",
    "        train_loss_list.append(train_loss/len(train_loader.dataset))\n",
    "        train_acc_list.append(accuracy.item())\n",
    "            \n",
    "        \n",
    "        # define NN evaluation, i.e. turn off dropouts, batchnorms, etc.\n",
    "        loss, acc = get_loss(net, val_loader)\n",
    "        val_loss_list.append(loss)\n",
    "        val_acc_list.append(acc)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_acc_list[-1])\n",
    "\n",
    "        if save and val_acc_list[-1] > best_val_acc:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + 'best_acc_model_' + model_name)    \n",
    "            best_val_acc = val_acc_list[-1]\n",
    "            \n",
    "        if save and val_loss_list[-1] < best_val_loss:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + 'best_val_loss_model_' + model_name)\n",
    "            best_val_loss = val_loss_list[-1]\n",
    "            \n",
    "        if save and epoch%5==0:\n",
    "            torch.save(net.state_dict(), CHECKPOINTS_DIR + str(epoch) + '_epoch_model_' + model_name)\n",
    "            \n",
    "        freq = 1\n",
    "        if verbose and epoch%freq==0:\n",
    "            print('Epoch {:02d}/{} || Loss:  Train {:.4f} | Validation {:.4f} Acc: Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, train_loss_list[-1], val_loss_list[-1], train_acc_list[-1], val_acc_list[-1] ))\n",
    "        if experiment:\n",
    "                experiment.log_metric(\"train_loss\", train_loss_list[-1])\n",
    "                experiment.log_metric(\"validate_loss\", val_loss_list[-1])\n",
    "                experiment.log_metric(\"train_acc\", train_acc_list[-1])\n",
    "                experiment.log_metric(\"validate_acc\", val_acc_list[-1])\n",
    "                experiment.log_epoch_end(epoch)\n",
    "    return train_loss_list, val_loss_list, train_acc_list, val_acc_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR =  '/home/checkpoints_torchion_crop_resize/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MriNetGrad(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super(MriNetGrad, self).__init__()\n",
    "        self.features = nn.Sequential( \n",
    "                nn.Conv3d(1, c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3, stride=2,),\n",
    "                \n",
    "                nn.Conv3d(c, 2*c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(2*c),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool3d(kernel_size=3, stride=2),\n",
    "                \n",
    "                nn.Conv3d(2*c, 4*c, kernel_size=3, stride=1, dilation=1, padding=0),\n",
    "                nn.BatchNorm3d(4*c),\n",
    "                nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1896960, out_features=2), #4*c*5*7*5\n",
    "        )\n",
    "        self.gradients = None\n",
    "        \n",
    "     \n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    def get_activations(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "c = 32\n",
    "model = MriNetGrad(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use [3, 4] GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=1896960, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "      d_ids= [3,4]\n",
    "      print(\"Let's use\", d_ids, \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      model = nn.DataParallel(model, device_ids=d_ids)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.NLLLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) #return ADAM?\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '_checkpoints_torchio_crop_resize'\n",
    "experiment.set_name(\"3DCNN_checkpoints_torchio_crop_resize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [1:01:52<00:00, 16.65s/it]\n",
      "100%|██████████| 112/112 [08:07<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00/60 || Loss:  Train 0.6934 | Validation 0.6934\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "EPOCHS = 60\n",
    "\n",
    "train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(EPOCHS, model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, save=True, experiment= experiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MriNetGrad(\n",
       "    (features): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): MaxPool3d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (9): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=1896960, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/home/checkpoints_rot_spcrop/best_acc_model__checkpoints_crop_scale'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [01:50<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.06726837158203, 0.9515447154471545, 0.9320388349514563, 0.96)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metric(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/223 [00:00<?, ?it/s]/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\n",
      "  warnings.warn(\"Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\")\n",
      "100%|██████████| 223/223 [11:50<00:00,  3.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94.60067749023438,\n",
       " 0.5198318839397678,\n",
       " 0.4792176039119804,\n",
       " 0.48157248157248156)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metric(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
